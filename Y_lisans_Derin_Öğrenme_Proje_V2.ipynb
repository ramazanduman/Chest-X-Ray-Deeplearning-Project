{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tOA5QqWfGLmOcox0OTmjGR3BgeNGAedG",
      "authorship_tag": "ABX9TyM5a2fTvjUl1uNrCD1YKqw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramazanduman/Chest-X-Ray-Deeplearning-Project/blob/main/Y_lisans_Derin_%C3%96%C4%9Frenme_Proje_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer, DefaultDataCollator, ViTConfig\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision.models as models # for CNN models\n",
        "import torch.nn as nn # Added for neural network layers\n",
        "!pip install -q evaluate # Ensure evaluate is installed\n",
        "!pip install -q  accelerate transformers evaluate\n",
        "\n",
        "\n",
        "\n",
        "# 1. Gerekli KÃ¼tÃ¼phanelerin Kurulumu\n",
        "!pip install -q datasets transformers evaluate accelerate torch torchvision\n",
        "\n",
        "# 2. Import Ä°ÅŸlemleri\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cihaz kontrolÃ¼ (GPU var mÄ±?)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"KullanÄ±lan Cihaz: {device}\")"
      ],
      "metadata": {
        "id": "bQHyw3hKPyja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Veri Setini YÃ¼kleme\n",
        "print(\"Veri seti Hugging Face Hub Ã¼zerinden indiriliyor...\")\n",
        "dataset = load_dataset(\"AiresPucrs/chest-xray\")\n",
        "\n",
        "# 4. Veri Seti YapÄ±sÄ±nÄ± Ä°nceleme\n",
        "print(\"\\n--- Veri Seti Genel YapÄ±sÄ± ---\")\n",
        "print(dataset)\n",
        "\n",
        "# SÄ±nÄ±f etiketlerini kontrol edelim\n",
        "# DokÃ¼mana gÃ¶re: 0 -> NORMAL, 1 -> PNEUMONIA olmalÄ± [cite: 13]\n",
        "print(f\"\\nÃ–zellikler: {dataset['train'].features}\")"
      ],
      "metadata": {
        "id": "1qSp6pe81NvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX4u-WPcN-IM"
      },
      "outputs": [],
      "source": [
        "# Veri setinin bÃ¶lÃ¼mlerini kontrol et\n",
        "if 'test' not in dataset:\n",
        "    print(\"\\nVeri seti hazÄ±r bÃ¶lÃ¼nmÃ¼ÅŸ gelmedi. %80-%20 olarak biz bÃ¶lÃ¼yoruz...\")\n",
        "    # Veriyi karÄ±ÅŸtÄ±rÄ±p bÃ¶lÃ¼yoruz (Seed sabitliyoruz ki sonuÃ§ deÄŸiÅŸmesin)\n",
        "    ds_split = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "    train_ds = ds_split['train']\n",
        "    test_ds = ds_split['test']\n",
        "else:\n",
        "    print(\"\\nVeri seti hazÄ±r bÃ¶lÃ¼nmÃ¼ÅŸ geldi, kontrol ediliyor...\")\n",
        "    train_ds = dataset['train']\n",
        "    test_ds = dataset['test']\n",
        "\n",
        "# SayÄ±larÄ± raporlayalÄ±m\n",
        "print(f\"\\nEÄŸitim Verisi SayÄ±sÄ±: {len(train_ds)}\")\n",
        "print(f\"Test Verisi SayÄ±sÄ±: {len(test_ds)}\")\n",
        "\n",
        "total = len(train_ds) + len(test_ds)\n",
        "print(f\"GerÃ§ekleÅŸen Oran -> EÄŸitim: %{len(train_ds)/total*100:.1f}, Test: %{len(test_ds)/total*100:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rastgele birkaÃ§ gÃ¶rÃ¼ntÃ¼ Ã§izdirelim\n",
        "def show_samples(ds, num_samples=4):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(0, len(ds))\n",
        "        image = ds[idx]['image']\n",
        "        label = ds[idx]['label']\n",
        "\n",
        "        # Label ismini bulma (features'dan)\n",
        "        label_name = ds.features['label'].int2str(label)\n",
        "\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"{label_name} ({label})\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- EÄŸitim Verisinden Ã–rnekler ---\")\n",
        "show_samples(train_ds)"
      ],
      "metadata": {
        "id": "vmajEFUrO8SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. DÃ¶nÃ¼ÅŸÃ¼m (Transform) TanÄ±mlarÄ±\n",
        "# GÃ¶rÃ¼ntÃ¼leri 224x224 yapacaÄŸÄ±z (ViT ve ResNet standart giriÅŸi)\n",
        "# RGB'ye Ã§eviriyoruz ki ilerideki modellerde kanal sayÄ±sÄ± hatasÄ± almayalÄ±m.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 2. DÃ¶nÃ¼ÅŸÃ¼mÃ¼ Veri Setine Uygulama Fonksiyonu\n",
        "def apply_transforms(examples):\n",
        "    # GÃ¶rÃ¼ntÃ¼lerin hepsi RGB olmayabilir, garantiye alÄ±yoruz (.convert(\"RGB\"))\n",
        "    examples[\"pixel_values\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "    return examples\n",
        "\n",
        "# Veri setine dÃ¶nÃ¼ÅŸÃ¼mleri anlÄ±k (on-the-fly) uygulanacak ÅŸekilde atÄ±yoruz\n",
        "train_ds.set_transform(apply_transforms)\n",
        "test_ds.set_transform(apply_transforms)\n",
        "\n",
        "# 3. DataLoader iÃ§in Collate Fonksiyonu\n",
        "# Verileri batch (paket) haline getirirken Tensor yÄ±ÄŸÄ±nÄ±na (stack) Ã§evirir\n",
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
        "    labels = torch.tensor([item[\"label\"] for item in batch])\n",
        "    return pixel_values, labels\n",
        "\n",
        "# 4. DataLoader OluÅŸturma\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Kontrol edelim\n",
        "batch_img, batch_label = next(iter(train_loader))\n",
        "print(f\"Batch GÃ¶rÃ¼ntÃ¼ Boyutu: {batch_img.shape}\") # Beklenen: [32, 3, 224, 224]\n",
        "print(f\"Batch Etiket Boyutu: {batch_label.shape}\") # Beklenen: [32]"
      ],
      "metadata": {
        "id": "7SizieZfPAuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # --- 1. KonvolÃ¼syon BloÄŸu ---\n",
        "        # GiriÅŸ: 3 kanal (RGB), Ã‡Ä±kÄ±ÅŸ: 32 filtre\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) # BatchNorm\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling\n",
        "\n",
        "        # --- 2. KonvolÃ¼syon BloÄŸu ---\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # --- 3. KonvolÃ¼syon BloÄŸu ---\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # --- 4. KonvolÃ¼syon BloÄŸu (Opsiyonel, derinliÄŸi artÄ±rmak iÃ§in) ---\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # --- SÄ±nÄ±flandÄ±rma KatmanÄ± (Dense/Linear) ---\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Hesaplama: 224 -> 112 -> 56 -> 28 -> 14 (4 kez pooling yapÄ±ldÄ±)\n",
        "        # Son boyut: 256 kanal * 14 * 14\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "        self.dropout = nn.Dropout(0.5) # Overfitting engellemek iÃ§in\n",
        "        self.fc2 = nn.Linear(512, num_classes) # Ã‡Ä±kÄ±ÅŸ: 2 (Normal vs Pneumonia) [cite: 6]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Blok 1\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        # Blok 2\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        # Blok 3\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        # Blok 4\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        # SÄ±nÄ±flandÄ±rma\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Modeli BaÅŸlatma ve Cihaza GÃ¶nderme\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "\n",
        "# Model Ã–zeti\n",
        "print(model)\n",
        "\n",
        "# Test AmaÃ§lÄ± Bir GeÃ§iÅŸ (Forward Pass)\n",
        "# OluÅŸturduÄŸumuz batch'i modelden geÃ§irip boyut kontrolÃ¼ yapalÄ±m\n",
        "with torch.no_grad():\n",
        "    dummy_output = model(batch_img.to(device))\n",
        "    print(f\"\\nModel Ã‡Ä±kÄ±ÅŸ Boyutu: {dummy_output.shape}\") # Beklenen: [32, 2]"
      ],
      "metadata": {
        "id": "Dyq6O43nTgMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm # Ä°lerleme Ã§ubuÄŸu iÃ§in\n",
        "\n",
        "# 1. Hiperparametreler ve Ayarlar\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10 # BaÅŸlangÄ±Ã§ iÃ§in 10 epoch yeterli olacaktÄ±r\n",
        "\n",
        "# KayÄ±p Fonksiyonu ve Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 2. EÄŸitim Fonksiyonu\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    # Metrikleri saklamak iÃ§in listeler\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'test_loss': [], 'test_acc': []\n",
        "    }\n",
        "\n",
        "    print(f\"EÄŸitim {device} Ã¼zerinde baÅŸlÄ±yor...\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # --- TRAINING PHASE (EÄŸitim AÅŸamasÄ±) ---\n",
        "        model.train() # Modeli eÄŸitim moduna al (Dropout/BatchNorm aktif)\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # tqdm ile ilerleme Ã§ubuÄŸu ekleyelim\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", unit=\"batch\")\n",
        "\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 1. Gradients sÄ±fÄ±rla\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 2. Forward Pass (Ä°leri yayÄ±lÄ±m)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 3. Backward Pass ve Optimize (Geri yayÄ±lÄ±m)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Ä°statistikleri topla\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "            # Pbar gÃ¼ncelleme\n",
        "            pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = correct_train / total_train\n",
        "\n",
        "        # --- VALIDATION PHASE (Test AÅŸamasÄ±) ---\n",
        "        model.eval() # Modeli deÄŸerlendirme moduna al\n",
        "        running_test_loss = 0.0\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad(): # Gradyan hesaplama, bellek tasarrufu yap\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_test_loss = running_test_loss / len(test_loader.dataset)\n",
        "        epoch_test_acc = correct_test / total_test\n",
        "\n",
        "        # GeÃ§miÅŸe kaydet\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc)\n",
        "        history['test_loss'].append(epoch_test_loss)\n",
        "        history['test_acc'].append(epoch_test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} Sonucu:\")\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: %{epoch_acc*100:.2f}\")\n",
        "        print(f\"Test  Loss: {epoch_test_loss:.4f} | Test  Acc: %{epoch_test_acc*100:.2f}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'EÄŸitim tamamlandÄ±! Toplam sÃ¼re: {time_elapsed // 60:.0f}dk {time_elapsed % 60:.0f}sn')\n",
        "    print(f'En iyi Test DoÄŸruluÄŸu: %{max(history[\"test_acc\"])*100:.2f}')\n",
        "\n",
        "    return history\n",
        "\n",
        "# 3. EÄŸitimi Ã‡alÄ±ÅŸtÄ±r\n",
        "history = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n"
      ],
      "metadata": {
        "id": "LNGPOqpkVBD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafik Ã§izdirme fonksiyonu\n",
        "def plot_history(history):\n",
        "    acc = history['train_acc']\n",
        "    val_acc = history['test_acc']\n",
        "    loss = history['train_loss']\n",
        "    val_loss = history['test_loss']\n",
        "    epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # DoÄŸruluk GrafiÄŸi\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='EÄŸitim DoÄŸruluÄŸu (Train Acc)')\n",
        "    plt.plot(epochs_range, val_acc, label='Test DoÄŸruluÄŸu (Test Acc)')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('EÄŸitim ve Test DoÄŸruluÄŸu')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # KayÄ±p (Loss) GrafiÄŸi\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='EÄŸitim KaybÄ± (Train Loss)')\n",
        "    plt.plot(epochs_range, val_loss, label='Test KaybÄ± (Test Loss)')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('EÄŸitim ve Test KaybÄ±')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "U1QxxZ5bVEyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50 ile devam\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Ã–nceden EÄŸitilmiÅŸ ResNet50 Modelini YÃ¼kle\n",
        "# 'weights=models.ResNet50_Weights.IMAGENET1K_V1' parametresi, modelin ImageNet aÄŸÄ±rlÄ±klarÄ±yla gelmesini saÄŸlar.\n",
        "print(\"ResNet50 Modeli Ä°ndiriliyor...\")\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
        "resnet_model = models.resnet50(weights=weights)\n",
        "\n",
        "# 2. Modelin Son KatmanÄ±nÄ± (Classifier) DeÄŸiÅŸtirme\n",
        "# ResNet50'nin orijinal Ã§Ä±kÄ±ÅŸÄ± 1000 sÄ±nÄ±ftÄ±r (ImageNet). Biz bunu 2 sÄ±nÄ±fa (Normal, Pneumonia) dÃ¼ÅŸÃ¼receÄŸiz.\n",
        "num_ftrs = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# 3. Modeli GPU'ya TaÅŸÄ±\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "print(\"\\n--- Model YapÄ±sÄ± (Son Katman) ---\")\n",
        "print(resnet_model.fc) # Ã‡Ä±ktÄ±: Linear(in_features=2048, out_features=2, bias=True)\n",
        "\n",
        "# 4. Optimizer ve Loss AyarlarÄ±\n",
        "# Transfer Learning'de genelde Ã¶ÄŸrenme hÄ±zÄ± (learning rate) biraz daha dÃ¼ÅŸÃ¼k tutulur.\n",
        "resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0001)\n",
        "resnet_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 5. EÄŸitimi BaÅŸlat (Mevcut train_model fonksiyonunu kullanÄ±yoruz)\n",
        "print(\"\\nResNet50 EÄŸitimi BaÅŸlÄ±yor...\")\n",
        "resnet_history = train_model(\n",
        "    model=resnet_model,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    criterion=resnet_criterion,\n",
        "    optimizer=resnet_optimizer,\n",
        "    num_epochs=5 # ResNet gÃ¼Ã§lÃ¼ olduÄŸu iÃ§in 5 epoch bile Ã§ok iyi sonuÃ§ verebilir\n",
        ")"
      ],
      "metadata": {
        "id": "PB0wEhyZTlV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SonuÃ§larÄ± Ã§izdir\n",
        "plot_history(resnet_history)\n",
        "\n",
        "# En iyi doÄŸruluk deÄŸerini yazdÄ±r\n",
        "print(f\"ResNet50 En Ä°yi Test DoÄŸruluÄŸu: %{max(resnet_history['test_acc'])*100:.2f}\")"
      ],
      "metadata": {
        "id": "t4V2CH9e_PQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer (ViT) Modeli\n",
        "\n",
        "from transformers import ViTForImageClassification, ViTConfig\n",
        "\n",
        "# 1. ViT Modelini HazÄ±rlama\n",
        "print(\"ViT Modeli (google/vit-base-patch16-224) Ä°ndiriliyor...\")\n",
        "\n",
        "# Etiket haritalamasÄ± (Raporlamada iÅŸe yarar)\n",
        "id2label = {0: \"NORMAL\", 1: \"PNEUMONIA\"}\n",
        "label2id = {\"NORMAL\": 0, \"PNEUMONIA\": 1}\n",
        "\n",
        "# Modeli yÃ¼kle\n",
        "vit_model_hf = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True # Ã‡Ä±kÄ±ÅŸ katmanÄ±nÄ± bizim 2 sÄ±nÄ±fÄ±mÄ±za gÃ¶re yeniden boyutlandÄ±rÄ±r\n",
        ")\n",
        "\n",
        "# 2. Model Wrapper (UyarlayÄ±cÄ±)\n",
        "# Hugging Face modelleri 'output.logits' dÃ¶ndÃ¼rÃ¼r, bizim dÃ¶ngÃ¼mÃ¼z direkt tensor bekliyor.\n",
        "# Bu sÄ±nÄ±f aradaki uyumu saÄŸlar.\n",
        "class ViTWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(ViTWrapper, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ViT 'pixel_values' argÃ¼manÄ± ister\n",
        "        outputs = self.model(pixel_values=x)\n",
        "        return outputs.logits\n",
        "\n",
        "# Wrapper ile modeli sarÄ±yoruz\n",
        "vit_model = ViTWrapper(vit_model_hf)\n",
        "vit_model = vit_model.to(device)\n",
        "\n",
        "# 3. Optimizer AyarlarÄ±\n",
        "# ViT iÃ§in genelde learning rate biraz daha dÃ¼ÅŸÃ¼k tutulur (2e-5 veya 5e-5 gibi)\n",
        "vit_optimizer = torch.optim.Adam(vit_model.parameters(), lr=5e-5)\n",
        "vit_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 4. EÄŸitimi BaÅŸlat\n",
        "print(\"\\nVision Transformer (ViT) EÄŸitimi BaÅŸlÄ±yor...\")\n",
        "# ViT daha kompleks olduÄŸu iÃ§in yine 5 epoch yeterli olacaktÄ±r, hatta 3. epochta bile sonuÃ§ verebilir.\n",
        "vit_history = train_model(\n",
        "    model=vit_model,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    criterion=vit_criterion,\n",
        "    optimizer=vit_optimizer,\n",
        "    num_epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "gQQix51OKeaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ViT SonuÃ§larÄ±nÄ± Ã‡izdir\n",
        "plot_history(vit_history)\n",
        "\n",
        "# En iyi skoru yazdÄ±r\n",
        "print(f\"ViT En Ä°yi Test DoÄŸruluÄŸu: %{max(vit_history['test_acc'])*100:.2f}\")"
      ],
      "metadata": {
        "id": "05fmczBRK2QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 1: Veri Seti AyarlarÄ±nÄ± Onarma ---\n",
        "# HafÄ±zadaki test_ds nesnesinin dÃ¶nÃ¼ÅŸÃ¼m fonksiyonunu tekrar tanÄ±mlayÄ±p atÄ±yoruz.\n",
        "# Bu iÅŸlem 'NoneType' hatasÄ±nÄ± ortadan kaldÄ±rÄ±r.\n",
        "\n",
        "def apply_transforms(examples):\n",
        "    examples[\"pixel_values\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "    return examples\n",
        "\n",
        "# Veri setini eski Ã§alÄ±ÅŸan haline getiriyoruz\n",
        "test_ds.set_transform(apply_transforms)\n",
        "print(\"âœ… Veri seti ayarlarÄ± onarÄ±ldÄ±.\")\n",
        "\n",
        "# Gerekli kÃ¼tÃ¼phaneyi yÃ¼kle\n",
        "!pip install -q grad-cam\n",
        "\n",
        "# --- ADIM 2: Grad-CAM GÃ¶rselleÅŸtirme (Garantili YÃ¶ntem) ---\n",
        "# Bu yÃ¶ntem, ham gÃ¶rÃ¼ntÃ¼ye eriÅŸmek yerine elimizdeki Tensor'u\n",
        "# matematiksel olarak geri Ã§evirip gÃ¶rselleÅŸtirir. Hata riskini sÄ±fÄ±ra indirir.\n",
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ResNet50'nin son katmanÄ±na kanca atÄ±yoruz\n",
        "target_layers = [resnet_model.layer4[-1]]\n",
        "cam = GradCAM(model=resnet_model, target_layers=target_layers)\n",
        "\n",
        "# Tensor (Normalize edilmiÅŸ) -> Orijinal GÃ¶rÃ¼ntÃ¼ (GÃ¶rselleÅŸtirmek iÃ§in)\n",
        "def inverse_normalize(tensor):\n",
        "    # (C, H, W) -> (H, W, C) formatÄ±na Ã§evir\n",
        "    img = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    # Normalize iÅŸlemini geri al: (img * std) + mean\n",
        "    # Daha Ã¶nce mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5] kullanmÄ±ÅŸtÄ±k\n",
        "    img = img * 0.5 + 0.5\n",
        "    # 0 ile 1 arasÄ±na sÄ±kÄ±ÅŸtÄ±r\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "def visualize_gradcam_final(model, dataset, num_samples=4):\n",
        "    model.eval()\n",
        "    print(\"PnÃ¶moni Ã¶rnekleri Ã¼zerinde analiz yapÄ±lÄ±yor...\")\n",
        "\n",
        "    # Rastgele pnÃ¶moni Ã¶rnekleri bulalÄ±m\n",
        "    found_samples = []\n",
        "    indices = np.random.permutation(len(dataset)) # Rastgele tara\n",
        "\n",
        "    for idx in indices:\n",
        "        item = dataset[int(idx)]\n",
        "        if item['label'] == 1: # Sadece PNEUMONIA\n",
        "            found_samples.append(item)\n",
        "            if len(found_samples) == num_samples:\n",
        "                break\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "\n",
        "    for i, item in enumerate(found_samples):\n",
        "        # Modelin beklediÄŸi input\n",
        "        input_tensor = item['pixel_values'].unsqueeze(0).to(device)\n",
        "\n",
        "        # 1. Grad-CAM (IsÄ± HaritasÄ±) Hesapla\n",
        "        grayscale_cam = cam(input_tensor=input_tensor, targets=None)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "        # 2. GÃ¶rÃ¼ntÃ¼yÃ¼ Ä°nsan GÃ¶zÃ¼ Ä°Ã§in Geri Ã‡evir\n",
        "        rgb_img = inverse_normalize(item['pixel_values'])\n",
        "\n",
        "        # 3. BirleÅŸtir\n",
        "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        # 4. Ã‡izdir\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(visualization)\n",
        "        plt.title(\"Modelin Karar BÃ¶lgesi\\n(KÄ±rmÄ±zÄ± Alan)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Ã‡alÄ±ÅŸtÄ±r\n",
        "visualize_gradcam_final(resnet_model, test_ds, num_samples=4)"
      ],
      "metadata": {
        "id": "JS-j7KrrXX6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# KayÄ±t yolu\n",
        "save_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Models'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# ResNet Modelini Kaydet\n",
        "torch.save(resnet_model.state_dict(), os.path.join(save_path, 'resnet50_pneumonia.pth'))\n",
        "\n",
        "# ViT Modelini Kaydet\n",
        "torch.save(vit_model.state_dict(), os.path.join(save_path, 'vit_pneumonia.pth'))\n",
        "\n",
        "print(f\"Modeller {save_path} klasÃ¶rÃ¼ne kaydedildi.\")"
      ],
      "metadata": {
        "id": "wFjq9qb7ahCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "# 1. KayÄ±t KlasÃ¶rÃ¼nÃ¼ Belirleme\n",
        "# Proje klasÃ¶rÃ¼nÃ¼zÃ¼n altÄ±na 'Model_Outputs' adÄ±nda bir klasÃ¶r aÃ§alÄ±m\n",
        "project_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi'\n",
        "save_path = os.path.join(project_path, 'Model_Outputs')\n",
        "\n",
        "# KlasÃ¶r yoksa oluÅŸtur\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "print(f\"ğŸ“‚ KayÄ±t klasÃ¶rÃ¼ hazÄ±rlandÄ±: {save_path}\")\n",
        "\n",
        "# --- 2. Modelleri Kaydetme (.pth dosyalarÄ±) ---\n",
        "print(\"\\nğŸ’¾ Modeller kaydediliyor...\")\n",
        "\n",
        "# Baseline CNN\n",
        "if 'model' in locals():\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, 'baseline_cnn.pth'))\n",
        "    print(\"âœ… Baseline CNN kaydedildi.\")\n",
        "\n",
        "# ResNet50\n",
        "if 'resnet_model' in locals():\n",
        "    torch.save(resnet_model.state_dict(), os.path.join(save_path, 'resnet50.pth'))\n",
        "    print(\"âœ… ResNet50 kaydedildi.\")\n",
        "\n",
        "# Vision Transformer (ViT)\n",
        "if 'vit_model' in locals():\n",
        "    torch.save(vit_model.state_dict(), os.path.join(save_path, 'vit_base.pth'))\n",
        "    print(\"âœ… ViT Model kaydedildi.\")\n",
        "\n",
        "# --- 3. EÄŸitim GeÃ§miÅŸini Kaydetme (Grafikler iÃ§in veriler) ---\n",
        "print(\"\\nğŸ“Š EÄŸitim geÃ§miÅŸleri (History) kaydediliyor...\")\n",
        "\n",
        "histories = {}\n",
        "if 'history' in locals(): histories['cnn'] = history\n",
        "if 'resnet_history' in locals(): histories['resnet'] = resnet_history\n",
        "if 'vit_history' in locals(): histories['vit'] = vit_history\n",
        "\n",
        "# Pickle modÃ¼lÃ¼ ile sÃ¶zlÃ¼k yapÄ±sÄ±nÄ± dosyaya dÃ¶kÃ¼yoruz\n",
        "with open(os.path.join(save_path, 'training_histories.pkl'), 'wb') as f:\n",
        "    pickle.dump(histories, f)\n",
        "\n",
        "print(f\"âœ… TÃ¼m eÄŸitim geÃ§miÅŸleri 'training_histories.pkl' dosyasÄ±na kaydedildi.\")\n",
        "print(\"\\nğŸ‰ TÃ¼m iÅŸlem tamamlandÄ±! Google Drive'Ä±nÄ±zÄ± kontrol edebilirsiniz.\")"
      ],
      "metadata": {
        "id": "soZEnrPpbHWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Tahmin Fonksiyonu (TÃ¼m modeller iÃ§in ortak)\n",
        "def get_all_predictions(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # TensÃ¶rleri CPU'ya alÄ±p listeye ekleyeceÄŸiz\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# 2. Matris Ã‡izdirme ve Kaydetme Fonksiyonu\n",
        "def plot_and_save_cm(model, model_name, loader, classes, save_folder):\n",
        "    print(f\"\\n--- {model_name} Analizi BaÅŸlÄ±yor ---\")\n",
        "\n",
        "    # Tahminleri al\n",
        "    y_true, y_pred = get_all_predictions(model, loader, device)\n",
        "\n",
        "    # Matrisi Hesapla\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Raporu YazdÄ±r (Precision, Recall, F1-Score)\n",
        "    print(classification_report(y_true, y_pred, target_names=classes))\n",
        "\n",
        "    # GÃ¶rselleÅŸtirme\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.ylabel('GerÃ§ek Etiket (True Label)')\n",
        "    plt.xlabel('Tahmin Edilen (Predicted Label)')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "\n",
        "    # Kaydet\n",
        "    file_path = os.path.join(save_folder, f'confusion_matrix_{model_name}.png')\n",
        "    plt.savefig(file_path)\n",
        "    plt.show()\n",
        "    print(f\"âœ… Grafik kaydedildi: {file_path}\")\n",
        "\n",
        "# --- 3. Ã‡alÄ±ÅŸtÄ±rma KÄ±smÄ± ---\n",
        "\n",
        "# SÄ±nÄ±f isimleri (DokÃ¼mana gÃ¶re: 0=NORMAL, 1=PNEUMONIA)\n",
        "class_names = ['NORMAL', 'PNEUMONIA']\n",
        "save_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Model_Outputs'\n",
        "\n",
        "# a) Baseline CNN\n",
        "if 'model' in locals():\n",
        "    plot_and_save_cm(model, \"Baseline_CNN\", test_loader, class_names, save_path)\n",
        "\n",
        "# b) ResNet50\n",
        "if 'resnet_model' in locals():\n",
        "    plot_and_save_cm(resnet_model, \"ResNet50\", test_loader, class_names, save_path)\n",
        "\n",
        "# c) Vision Transformer (ViT)\n",
        "if 'vit_model' in locals():\n",
        "    plot_and_save_cm(vit_model, \"ViT_Base\", test_loader, class_names, save_path)"
      ],
      "metadata": {
        "id": "-vUMIzGdbqTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. KayÄ±tlÄ± verileri yÃ¼kle\n",
        "load_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Model_Outputs/training_histories.pkl'\n",
        "\n",
        "if os.path.exists(load_path):\n",
        "    with open(load_path, 'rb') as f:\n",
        "        histories = pickle.load(f)\n",
        "\n",
        "    # 2. Verileri Tabloya DÃ¶nÃ¼ÅŸtÃ¼r\n",
        "    results = []\n",
        "\n",
        "    # Modelleri dÃ¶ngÃ¼yle gez\n",
        "    for model_name, h in histories.items():\n",
        "        # En iyi test doÄŸruluÄŸu\n",
        "        best_acc = max(h['test_acc']) * 100\n",
        "        # Son epoch kaybÄ±\n",
        "        final_loss = h['test_loss'][-1]\n",
        "        # EÄŸitim doÄŸruluÄŸu (son epoch)\n",
        "        train_acc = h['train_acc'][-1] * 100\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": model_name.upper(),\n",
        "            \"En Ä°yi Test DoÄŸruluÄŸu (%)\": f\"%{best_acc:.2f}\",\n",
        "            \"EÄŸitim DoÄŸruluÄŸu (%)\": f\"%{train_acc:.2f}\",\n",
        "            \"Test KaybÄ± (Loss)\": f\"{final_loss:.4f}\"\n",
        "        })\n",
        "\n",
        "    # DataFrame oluÅŸtur\n",
        "    df_results = pd.DataFrame(results)\n",
        "\n",
        "    # Tabloyu gÃ¶ster\n",
        "    print(\"--- MODEL PERFORMANS KARÅILAÅTIRMASI ---\")\n",
        "    display(df_results)\n",
        "else:\n",
        "    print(\"KayÄ±tlÄ± geÃ§miÅŸ dosyasÄ± bulunamadÄ±. LÃ¼tfen eÄŸitim adÄ±mlarÄ±nÄ± tamamlayÄ±p kaydettiÄŸinizden emin olun.\")"
      ],
      "metadata": {
        "id": "PCb7Rp-h9yoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "plt.subplots(figsize=(8, 8))\n",
        "df_2dhist = pd.DataFrame({\n",
        "    x_label: grp['En Ä°yi Test DoÄŸruluÄŸu (%)'].value_counts()\n",
        "    for x_label, grp in df_results.groupby('Model')\n",
        "})\n",
        "sns.heatmap(df_2dhist, cmap='viridis')\n",
        "plt.xlabel('Model')\n",
        "_ = plt.ylabel('En Ä°yi Test DoÄŸruluÄŸu (%)')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_xbSd5nj-aRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68d81e76"
      },
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Bar Chart for 'En Ä°yi Test DoÄŸruluÄŸu (%)'\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.barplot(x='Model', y='En Ä°yi Test DoÄŸruluÄŸu (%)', data=df_results, palette='viridis', hue='Model', legend=False)\n",
        "plt.title('Modellerin En Ä°yi Test DoÄŸruluÄŸu (%)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('DoÄŸruluk (%)')\n",
        "plt.ylim(min(df_results['En Ä°yi Test DoÄŸruluÄŸu (%)']) - 1, max(df_results['En Ä°yi Test DoÄŸruluÄŸu (%)']) + 1)\n",
        "\n",
        "# Bar Chart for 'EÄŸitim DoÄŸruluÄŸu (%)'\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.barplot(x='Model', y='EÄŸitim DoÄŸruluÄŸu (%)', data=df_results, palette='magma', hue='Model', legend=False)\n",
        "plt.title('Modellerin EÄŸitim DoÄŸruluÄŸu (%)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('DoÄŸruluk (%)')\n",
        "plt.ylim(min(df_results['EÄŸitim DoÄŸruluÄŸu (%)']) - 1, max(df_results['EÄŸitim DoÄŸruluÄŸu (%)']) + 1)\n",
        "\n",
        "# Bar Chart for 'Test KaybÄ± (Loss)'\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.barplot(x='Model', y='Test KaybÄ± (Loss)', data=df_results, palette='plasma', hue='Model', legend=False)\n",
        "plt.title('Modellerin Test KaybÄ± (Loss)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('KayÄ±p (Loss)')\n",
        "plt.ylim(min(df_results['Test KaybÄ± (Loss)']) - 0.05, max(df_results['Test KaybÄ± (Loss)']) + 0.05)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GEREKLÄ° KÃœTÃœPHANELER\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# DEVICE AYARI\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"KullanÄ±lan cihaz: {device}\")\n",
        "\n",
        "# VERÄ° KLASÃ–R YOLU\n",
        "TEST_DATA_PATH = \"/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/train/karma\"\n",
        "MODELS_PATH = \"/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Model_Outputs\"\n",
        "\n",
        "# SINIFLAR (dokÃ¼manÄ±nÄ±za gÃ¶re: 0=NORMAL, 1=PNEUMONIA)\n",
        "CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "# TRANSFORMLAR (eÄŸitimde kullandÄ±ÄŸÄ±nÄ±zla aynÄ± olmalÄ±)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Ã–ZEL DATASET SINIFI\n",
        "class PneumoniaDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # KlasÃ¶r yapÄ±sÄ±na gÃ¶re verileri yÃ¼kle\n",
        "        for label, class_name in enumerate(CLASS_NAMES):\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        self.image_paths.append(os.path.join(class_dir, img_name))\n",
        "                        self.labels.append(label)\n",
        "\n",
        "        print(f\"Toplam {len(self.image_paths)} gÃ¶rÃ¼ntÃ¼ yÃ¼klendi\")\n",
        "        print(f\"SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±: NORMAL={self.labels.count(0)}, PNEUMONIA={self.labels.count(1)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, img_path\n",
        "\n",
        "# VERÄ° SETÄ°NÄ° YÃœKLE\n",
        "print(\"=\" * 50)\n",
        "print(\"TEST VERÄ° SETÄ° YÃœKLENÄ°YOR...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_dataset = PneumoniaDataset(TEST_DATA_PATH, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# MODEL TANIMLARI (eÄŸitimdeki yapÄ±larla aynÄ± olmalÄ±)\n",
        "\n",
        "# 1. BASELINE CNN MODELÄ° (eÄŸitimdeki yapÄ±yla aynÄ±)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 2. VISION TRANSFORMER WRAPPER (eÄŸitimdeki yapÄ±yla aynÄ±)\n",
        "from transformers import ViTForImageClassification\n",
        "\n",
        "class ViTWrapper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViTWrapper, self).__init__()\n",
        "        # Base model - eÄŸitimdeki yapÄ±yla aynÄ±\n",
        "        self.model = ViTForImageClassification.from_pretrained(\n",
        "            \"google/vit-base-patch16-224\",\n",
        "            num_labels=2,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.model(pixel_values=x)\n",
        "        return outputs.logits\n",
        "\n",
        "# MODELLERÄ° YÃœKLEME FONKSÄ°YONU\n",
        "def load_model(model_name, model_path):\n",
        "    \"\"\"KaydedilmiÅŸ modeli yÃ¼kle\"\"\"\n",
        "    full_path = os.path.join(model_path, f\"{model_name}.pth\")\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        raise FileNotFoundError(f\"Model dosyasÄ± bulunamadÄ±: {full_path}\")\n",
        "\n",
        "    print(f\"\\nğŸ“‚ {model_name} modeli yÃ¼kleniyor...\")\n",
        "\n",
        "    if model_name == \"baseline_cnn\":\n",
        "        model = SimpleCNN(num_classes=2)\n",
        "        model.load_state_dict(torch.load(full_path, map_location=device))\n",
        "\n",
        "    elif model_name == \"resnet50\":\n",
        "        model = models.resnet50(pretrained=False)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 2)\n",
        "        model.load_state_dict(torch.load(full_path, map_location=device))\n",
        "\n",
        "    elif model_name == \"vit_base\":\n",
        "        model = ViTWrapper()\n",
        "        model.load_state_dict(torch.load(full_path, map_location=device))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Bilinmeyen model: {model_name}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()  # DeÄŸerlendirme modu\n",
        "    print(f\"âœ… {model_name} modeli baÅŸarÄ±yla yÃ¼klendi\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# TEST FONKSÄ°YONU\n",
        "def evaluate_model(model, model_name, test_loader):\n",
        "    \"\"\"Modeli test setinde deÄŸerlendir\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{model_name.upper()} MODELÄ° DEÄERLENDÄ°RÄ°LÄ°YOR...\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    all_paths = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels, paths) in enumerate(tqdm(test_loader, desc=f\"Test - {model_name}\")):\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    # METRÄ°KLERÄ° HESAPLA\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"\\nğŸ“Š {model_name.upper()} PERFORMANS METRÄ°KLERÄ°:\")\n",
        "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "    # CLASSIFICATION REPORT\n",
        "    print(\"\\nğŸ“‹ Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))\n",
        "\n",
        "    # CONFUSION MATRIX\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "    plt.title(f'Confusion Matrix - {model_name.upper()}')\n",
        "    plt.ylabel('GerÃ§ek DeÄŸer')\n",
        "    plt.xlabel('Tahmin')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # GrafiÄŸi kaydet\n",
        "    cm_save_path = os.path.join(MODELS_PATH, f\"confusion_matrix_{model_name}_new_test.png\")\n",
        "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"âœ… Confusion matrix kaydedildi: {cm_save_path}\")\n",
        "\n",
        "    # YANLIÅ SINIFLANDIRMALARI ANALÄ°Z ET\n",
        "    errors = []\n",
        "    for i, (true, pred, prob, path) in enumerate(zip(all_labels, all_preds, all_probs, all_paths)):\n",
        "        if true != pred:\n",
        "            errors.append({\n",
        "                'image_path': path,\n",
        "                'true_class': CLASS_NAMES[true],\n",
        "                'pred_class': CLASS_NAMES[pred],\n",
        "                'confidence': max(prob),\n",
        "                'true_prob': prob[true],\n",
        "                'pred_prob': prob[pred]\n",
        "            })\n",
        "\n",
        "    if errors:\n",
        "        print(f\"\\nâš ï¸ {len(errors)} adet yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma tespit edildi\")\n",
        "\n",
        "        # En yÃ¼ksek confidence ile yanlÄ±ÅŸ yapan Ã¶rnekler\n",
        "        errors_sorted = sorted(errors, key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "        print(\"\\nğŸ”´ EN YÃœKSEK CONFIDENCE Ä°LE YANLIÅ YAPAN Ã–RNEKLER (ilk 5):\")\n",
        "        for i, error in enumerate(errors_sorted[:5]):\n",
        "            print(f\"{i+1}. {error['image_path']}\")\n",
        "            print(f\"   GerÃ§ek: {error['true_class']}, Tahmin: {error['pred_class']}\")\n",
        "            print(f\"   Confidence: {error['confidence']*100:.1f}%\")\n",
        "            print(f\"   GerÃ§ek sÄ±nÄ±f olasÄ±lÄ±ÄŸÄ±: {error['true_prob']*100:.1f}%\")\n",
        "            print()\n",
        "\n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels,\n",
        "        'probabilities': all_probs,\n",
        "        'errors': errors\n",
        "    }\n",
        "\n",
        "# TÃœM MODELLERÄ° TEST ET\n",
        "def test_all_models():\n",
        "    \"\"\"TÃ¼m kaydedilmiÅŸ modelleri test et\"\"\"\n",
        "\n",
        "    results = {}\n",
        "    model_names = [\"baseline_cnn\", \"resnet50\", \"vit_base\"]\n",
        "\n",
        "    for model_name in model_names:\n",
        "        try:\n",
        "            # Modeli yÃ¼kle\n",
        "            model = load_model(model_name, MODELS_PATH)\n",
        "\n",
        "            # Test et\n",
        "            result = evaluate_model(model, model_name, test_loader)\n",
        "            results[model_name] = result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ {model_name} modeli test edilirken hata: {e}\")\n",
        "            continue\n",
        "\n",
        "    # KARÅILAÅTIRMALI SONUÃ‡LAR\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MODEL PERFORMANS KARÅILAÅTIRMASI\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    comparison_data = []\n",
        "    for model_name, result in results.items():\n",
        "        comparison_data.append({\n",
        "            'Model': model_name.upper(),\n",
        "            'Test Accuracy (%)': f\"{result['accuracy']*100:.2f}\",\n",
        "            'YanlÄ±ÅŸ SayÄ±sÄ±': len(result['errors']),\n",
        "            'Toplam Ã–rnek': len(result['labels'])\n",
        "        })\n",
        "\n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "    print(\"\\nğŸ“ˆ PERFORMANS KARÅILAÅTIRMASI:\")\n",
        "    display(df_comparison)\n",
        "\n",
        "    # GRAFÄ°K OLUÅTUR\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    models_list = [r['Model'] for r in comparison_data]\n",
        "    accuracies = [float(r['Test Accuracy (%)'].replace('%', '')) for r in comparison_data]\n",
        "\n",
        "    bars = plt.bar(models_list, accuracies, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "    plt.xlabel('Modeller')\n",
        "    plt.ylabel('DoÄŸruluk (%)')\n",
        "    plt.title('Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±')\n",
        "    plt.ylim([0, 100])\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine yaz\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "                f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # GrafiÄŸi kaydet\n",
        "    graph_save_path = os.path.join(MODELS_PATH, \"model_comparison_new_test.png\")\n",
        "    plt.savefig(graph_save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"\\nâœ… KarÅŸÄ±laÅŸtÄ±rma grafiÄŸi kaydedildi: {graph_save_path}\")\n",
        "\n",
        "    # DETAYLI ANALÄ°Z\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DETAYLI ANALÄ°Z\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Her model iÃ§in hata analizi\n",
        "    for model_name, result in results.items():\n",
        "        if result['errors']:\n",
        "            # Hata tiplerini analiz et\n",
        "            error_types = {}\n",
        "            for error in result['errors']:\n",
        "                key = f\"{error['true_class']}â†’{error['pred_class']}\"\n",
        "                error_types[key] = error_types.get(key, 0) + 1\n",
        "\n",
        "            print(f\"\\nğŸ” {model_name.upper()} Hata DaÄŸÄ±lÄ±mÄ±:\")\n",
        "            for error_type, count in error_types.items():\n",
        "                percentage = (count / len(result['errors'])) * 100\n",
        "                print(f\"  {error_type}: {count} Ã¶rnek (%{percentage:.1f})\")\n",
        "\n",
        "    return results, df_comparison\n",
        "\n",
        "# YANLIÅ SINIFLANDIRILAN GÃ–RÃœNTÃœLERÄ° GÃ–RSELLEÅTÄ°R\n",
        "def visualize_errors(results, num_samples=5):\n",
        "    \"\"\"YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lan gÃ¶rÃ¼ntÃ¼leri gÃ¶ster\"\"\"\n",
        "\n",
        "    for model_name, result in results.items():\n",
        "        if result['errors']:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"{model_name.upper()} - YANLIÅ SINIFLANDIRILAN GÃ–RÃœNTÃœLER\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            # Rastgele Ã¶rnek seÃ§\n",
        "            error_samples = np.random.choice(result['errors'],\n",
        "                                            size=min(num_samples, len(result['errors'])),\n",
        "                                            replace=False)\n",
        "\n",
        "            fig, axes = plt.subplots(1, len(error_samples), figsize=(20, 4))\n",
        "            if len(error_samples) == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for idx, error in enumerate(error_samples):\n",
        "                try:\n",
        "                    img = Image.open(error['image_path']).convert(\"RGB\")\n",
        "                    img_resized = img.resize((224, 224))\n",
        "\n",
        "                    axes[idx].imshow(img_resized)\n",
        "                    axes[idx].set_title(\n",
        "                        f\"GerÃ§ek: {error['true_class']}\\n\"\n",
        "                        f\"Tahmin: {error['pred_class']}\\n\"\n",
        "                        f\"Conf: {error['confidence']*100:.1f}%\",\n",
        "                        fontsize=10\n",
        "                    )\n",
        "                    axes[idx].axis('off')\n",
        "\n",
        "                    # YanlÄ±ÅŸ sÄ±nÄ±f iÃ§in kenarlÄ±k rengi\n",
        "                    border_color = 'red' if error['pred_class'] == 'PNEUMONIA' else 'blue'\n",
        "                    for spine in axes[idx].spines.values():\n",
        "                        spine.set_edgecolor(border_color)\n",
        "                        spine.set_linewidth(3)\n",
        "\n",
        "                except Exception as e:\n",
        "                    axes[idx].text(0.5, 0.5, f\"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi\\n{str(e)[:30]}...\",\n",
        "                                 ha='center', va='center')\n",
        "                    axes[idx].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# ANA KODU Ã‡ALIÅTIR\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ¯ KAYDEDÄ°LMÄ°Å MODELLERLE TEST BAÅLIYOR...\")\n",
        "    print(f\"Test verisi: {TEST_DATA_PATH}\")\n",
        "    print(f\"Model yolu: {MODELS_PATH}\")\n",
        "    print(f\"Toplam test Ã¶rneÄŸi: {len(test_dataset)}\")\n",
        "\n",
        "    # TÃ¼m modelleri test et\n",
        "    results, comparison_df = test_all_models()\n",
        "\n",
        "    # YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ± gÃ¶rselleÅŸtir\n",
        "    visualize_errors(results, num_samples=3)\n",
        "\n",
        "    # SONUÃ‡LARI KAYDET\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SONUÃ‡LAR KAYDEDÄ°LÄ°YOR...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # DataFrame'i CSV olarak kaydet\n",
        "    csv_path = os.path.join(MODELS_PATH, \"model_test_results.csv\")\n",
        "    comparison_df.to_csv(csv_path, index=False)\n",
        "    print(f\"âœ… Test sonuÃ§larÄ± kaydedildi: {csv_path}\")\n",
        "\n",
        "    # DetaylÄ± sonuÃ§larÄ± pickle olarak kaydet\n",
        "    import pickle\n",
        "    results_path = os.path.join(MODELS_PATH, \"detailed_test_results.pkl\")\n",
        "    with open(results_path, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "    print(f\"âœ… DetaylÄ± sonuÃ§lar kaydedildi: {results_path}\")\n",
        "\n",
        "    print(\"\\nâœ… TÃœM TESTLER TAMAMLANDI! ğŸ‰\")"
      ],
      "metadata": {
        "id": "Yt7NYNhsQ7eh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}