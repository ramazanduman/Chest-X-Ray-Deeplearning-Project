{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1tOA5QqWfGLmOcox0OTmjGR3BgeNGAedG","authorship_tag":"ABX9TyNKou5mziRuosbhBK1juzEO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from datasets import load_dataset\n","import numpy as np\n","from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer, DefaultDataCollator, ViTConfig\n","\n","import os\n","import torch\n","import torchvision.models as models # for CNN models\n","import torch.nn as nn # Added for neural network layers\n","!pip install -q evaluate # Ensure evaluate is installed\n","!pip install -q  accelerate transformers evaluate\n","\n","\n","\n","# 1. Gerekli KÃ¼tÃ¼phanelerin Kurulumu\n","!pip install -q datasets transformers evaluate accelerate torch torchvision\n","\n","# 2. Import Ä°ÅŸlemleri\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","# Cihaz kontrolÃ¼ (GPU var mÄ±?)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"KullanÄ±lan Cihaz: {device}\")"],"metadata":{"id":"bQHyw3hKPyja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Veri Setini YÃ¼kleme\n","print(\"Veri seti Hugging Face Hub Ã¼zerinden indiriliyor...\")\n","dataset = load_dataset(\"AiresPucrs/chest-xray\")\n","\n","# 4. Veri Seti YapÄ±sÄ±nÄ± Ä°nceleme\n","print(\"\\n--- Veri Seti Genel YapÄ±sÄ± ---\")\n","print(dataset)\n","\n","# SÄ±nÄ±f etiketlerini kontrol edelim\n","# DokÃ¼mana gÃ¶re: 0 -> NORMAL, 1 -> PNEUMONIA olmalÄ± [cite: 13]\n","print(f\"\\nÃ–zellikler: {dataset['train'].features}\")"],"metadata":{"collapsed":true,"id":"1qSp6pe81NvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KX4u-WPcN-IM"},"outputs":[],"source":["# Veri setinin bÃ¶lÃ¼mlerini kontrol et\n","if 'test' not in dataset:\n","    print(\"\\nVeri seti hazÄ±r bÃ¶lÃ¼nmÃ¼ÅŸ gelmedi. %80-%20 olarak biz bÃ¶lÃ¼yoruz...\")\n","    # Veriyi karÄ±ÅŸtÄ±rÄ±p bÃ¶lÃ¼yoruz (Seed sabitliyoruz ki sonuÃ§ deÄŸiÅŸmesin)\n","    ds_split = dataset['train'].train_test_split(test_size=0.2, seed=42)\n","    train_ds = ds_split['train']\n","    test_ds = ds_split['test']\n","else:\n","    print(\"\\nVeri seti hazÄ±r bÃ¶lÃ¼nmÃ¼ÅŸ geldi, kontrol ediliyor...\")\n","    train_ds = dataset['train']\n","    test_ds = dataset['test']\n","\n","# SayÄ±larÄ± raporlayalÄ±m\n","print(f\"\\nEÄŸitim Verisi SayÄ±sÄ±: {len(train_ds)}\")\n","print(f\"Test Verisi SayÄ±sÄ±: {len(test_ds)}\")\n","\n","total = len(train_ds) + len(test_ds)\n","print(f\"GerÃ§ekleÅŸen Oran -> EÄŸitim: %{len(train_ds)/total*100:.1f}, Test: %{len(test_ds)/total*100:.1f}\")"]},{"cell_type":"code","source":["# Rastgele birkaÃ§ gÃ¶rÃ¼ntÃ¼ Ã§izdirelim\n","def show_samples(ds, num_samples=4):\n","    plt.figure(figsize=(12, 4))\n","    for i in range(num_samples):\n","        idx = np.random.randint(0, len(ds))\n","        image = ds[idx]['image']\n","        label = ds[idx]['label']\n","\n","        # Label ismini bulma (features'dan)\n","        label_name = ds.features['label'].int2str(label)\n","\n","        plt.subplot(1, num_samples, i + 1)\n","        plt.imshow(image, cmap='gray')\n","        plt.title(f\"{label_name} ({label})\")\n","        plt.axis('off')\n","    plt.show()\n","\n","print(\"\\n--- EÄŸitim Verisinden Ã–rnekler ---\")\n","show_samples(train_ds)"],"metadata":{"id":"vmajEFUrO8SB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. DÃ¶nÃ¼ÅŸÃ¼m (Transform) TanÄ±mlarÄ±\n","# GÃ¶rÃ¼ntÃ¼leri 224x224 yapacaÄŸÄ±z (ViT ve ResNet standart giriÅŸi)\n","# RGB'ye Ã§eviriyoruz ki ilerideki modellerde kanal sayÄ±sÄ± hatasÄ± almayalÄ±m.\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# 2. DÃ¶nÃ¼ÅŸÃ¼mÃ¼ Veri Setine Uygulama Fonksiyonu\n","def apply_transforms(examples):\n","    # GÃ¶rÃ¼ntÃ¼lerin hepsi RGB olmayabilir, garantiye alÄ±yoruz (.convert(\"RGB\"))\n","    examples[\"pixel_values\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image\"]]\n","    return examples\n","\n","# Veri setine dÃ¶nÃ¼ÅŸÃ¼mleri anlÄ±k (on-the-fly) uygulanacak ÅŸekilde atÄ±yoruz\n","train_ds.set_transform(apply_transforms)\n","test_ds.set_transform(apply_transforms)\n","\n","# 3. DataLoader iÃ§in Collate Fonksiyonu\n","# Verileri batch (paket) haline getirirken Tensor yÄ±ÄŸÄ±nÄ±na (stack) Ã§evirir\n","def collate_fn(batch):\n","    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n","    labels = torch.tensor([item[\"label\"] for item in batch])\n","    return pixel_values, labels\n","\n","# 4. DataLoader OluÅŸturma\n","BATCH_SIZE = 32\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n","\n","# Kontrol edelim\n","batch_img, batch_label = next(iter(train_loader))\n","print(f\"Batch GÃ¶rÃ¼ntÃ¼ Boyutu: {batch_img.shape}\") # Beklenen: [32, 3, 224, 224]\n","print(f\"Batch Etiket Boyutu: {batch_label.shape}\") # Beklenen: [32]"],"metadata":{"id":"7SizieZfPAuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super(SimpleCNN, self).__init__()\n","\n","        # --- 1. KonvolÃ¼syon BloÄŸu ---\n","        # GiriÅŸ: 3 kanal (RGB), Ã‡Ä±kÄ±ÅŸ: 32 filtre\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32) # BatchNorm\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling\n","\n","        # --- 2. KonvolÃ¼syon BloÄŸu ---\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","\n","        # --- 3. KonvolÃ¼syon BloÄŸu ---\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","\n","        # --- 4. KonvolÃ¼syon BloÄŸu (Opsiyonel, derinliÄŸi artÄ±rmak iÃ§in) ---\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","\n","        # --- SÄ±nÄ±flandÄ±rma KatmanÄ± (Dense/Linear) ---\n","        self.flatten = nn.Flatten()\n","\n","        # Hesaplama: 224 -> 112 -> 56 -> 28 -> 14 (4 kez pooling yapÄ±ldÄ±)\n","        # Son boyut: 256 kanal * 14 * 14\n","        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n","        self.dropout = nn.Dropout(0.5) # Overfitting engellemek iÃ§in\n","        self.fc2 = nn.Linear(512, num_classes) # Ã‡Ä±kÄ±ÅŸ: 2 (Normal vs Pneumonia) [cite: 6]\n","\n","    def forward(self, x):\n","        # Blok 1\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        # Blok 2\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        # Blok 3\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        # Blok 4\n","        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n","\n","        # SÄ±nÄ±flandÄ±rma\n","        x = self.flatten(x)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Modeli BaÅŸlatma ve Cihaza GÃ¶nderme\n","model = SimpleCNN(num_classes=2).to(device)\n","\n","# Model Ã–zeti\n","print(model)\n","\n","# Test AmaÃ§lÄ± Bir GeÃ§iÅŸ (Forward Pass)\n","# OluÅŸturduÄŸumuz batch'i modelden geÃ§irip boyut kontrolÃ¼ yapalÄ±m\n","with torch.no_grad():\n","    dummy_output = model(batch_img.to(device))\n","    print(f\"\\nModel Ã‡Ä±kÄ±ÅŸ Boyutu: {dummy_output.shape}\") # Beklenen: [32, 2]"],"metadata":{"id":"Dyq6O43nTgMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from tqdm import tqdm # Ä°lerleme Ã§ubuÄŸu iÃ§in\n","\n","# 1. Hiperparametreler ve Ayarlar\n","LEARNING_RATE = 0.001\n","NUM_EPOCHS = 10 # BaÅŸlangÄ±Ã§ iÃ§in 10 epoch yeterli olacaktÄ±r\n","\n","# KayÄ±p Fonksiyonu ve Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# 2. EÄŸitim Fonksiyonu\n","def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n","    since = time.time()\n","\n","    # Metrikleri saklamak iÃ§in listeler\n","    history = {\n","        'train_loss': [], 'train_acc': [],\n","        'test_loss': [], 'test_acc': []\n","    }\n","\n","    print(f\"EÄŸitim {device} Ã¼zerinde baÅŸlÄ±yor...\")\n","    print(\"-\" * 30)\n","\n","    for epoch in range(num_epochs):\n","        # --- TRAINING PHASE (EÄŸitim AÅŸamasÄ±) ---\n","        model.train() # Modeli eÄŸitim moduna al (Dropout/BatchNorm aktif)\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        # tqdm ile ilerleme Ã§ubuÄŸu ekleyelim\n","        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", unit=\"batch\")\n","\n","        for inputs, labels in pbar:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # 1. Gradients sÄ±fÄ±rla\n","            optimizer.zero_grad()\n","\n","            # 2. Forward Pass (Ä°leri yayÄ±lÄ±m)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # 3. Backward Pass ve Optimize (Geri yayÄ±lÄ±m)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Ä°statistikleri topla\n","            running_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","\n","            # Pbar gÃ¼ncelleme\n","            pbar.set_postfix({'loss': loss.item()})\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = correct_train / total_train\n","\n","        # --- VALIDATION PHASE (Test AÅŸamasÄ±) ---\n","        model.eval() # Modeli deÄŸerlendirme moduna al\n","        running_test_loss = 0.0\n","        correct_test = 0\n","        total_test = 0\n","\n","        with torch.no_grad(): # Gradyan hesaplama, bellek tasarrufu yap\n","            for inputs, labels in test_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                running_test_loss += loss.item() * inputs.size(0)\n","                _, predicted = torch.max(outputs, 1)\n","                total_test += labels.size(0)\n","                correct_test += (predicted == labels).sum().item()\n","\n","        epoch_test_loss = running_test_loss / len(test_loader.dataset)\n","        epoch_test_acc = correct_test / total_test\n","\n","        # GeÃ§miÅŸe kaydet\n","        history['train_loss'].append(epoch_loss)\n","        history['train_acc'].append(epoch_acc)\n","        history['test_loss'].append(epoch_test_loss)\n","        history['test_acc'].append(epoch_test_acc)\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} Sonucu:\")\n","        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: %{epoch_acc*100:.2f}\")\n","        print(f\"Test  Loss: {epoch_test_loss:.4f} | Test  Acc: %{epoch_test_acc*100:.2f}\")\n","        print(\"-\" * 30)\n","\n","    time_elapsed = time.time() - since\n","    print(f'EÄŸitim tamamlandÄ±! Toplam sÃ¼re: {time_elapsed // 60:.0f}dk {time_elapsed % 60:.0f}sn')\n","    print(f'En iyi Test DoÄŸruluÄŸu: %{max(history[\"test_acc\"])*100:.2f}')\n","\n","    return history\n","\n","# 3. EÄŸitimi Ã‡alÄ±ÅŸtÄ±r\n","history = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n"],"metadata":{"id":"LNGPOqpkVBD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Grafik Ã§izdirme fonksiyonu\n","def plot_history(history):\n","    acc = history['train_acc']\n","    val_acc = history['test_acc']\n","    loss = history['train_loss']\n","    val_loss = history['test_loss']\n","    epochs_range = range(1, len(acc) + 1)\n","\n","    plt.figure(figsize=(14, 5))\n","\n","    # DoÄŸruluk GrafiÄŸi\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs_range, acc, label='EÄŸitim DoÄŸruluÄŸu (Train Acc)')\n","    plt.plot(epochs_range, val_acc, label='Test DoÄŸruluÄŸu (Test Acc)')\n","    plt.legend(loc='lower right')\n","    plt.title('EÄŸitim ve Test DoÄŸruluÄŸu')\n","    plt.grid(True)\n","\n","    # KayÄ±p (Loss) GrafiÄŸi\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs_range, loss, label='EÄŸitim KaybÄ± (Train Loss)')\n","    plt.plot(epochs_range, val_loss, label='Test KaybÄ± (Test Loss)')\n","    plt.legend(loc='upper right')\n","    plt.title('EÄŸitim ve Test KaybÄ±')\n","    plt.grid(True)\n","\n","    plt.show()\n","\n","plot_history(history)"],"metadata":{"id":"U1QxxZ5bVEyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50 ile devam\n","from torchvision import models\n","import torch.nn as nn\n","\n","# 1. Ã–nceden EÄŸitilmiÅŸ ResNet50 Modelini YÃ¼kle\n","# 'weights=models.ResNet50_Weights.IMAGENET1K_V1' parametresi, modelin ImageNet aÄŸÄ±rlÄ±klarÄ±yla gelmesini saÄŸlar.\n","print(\"ResNet50 Modeli Ä°ndiriliyor...\")\n","weights = models.ResNet50_Weights.IMAGENET1K_V1\n","resnet_model = models.resnet50(weights=weights)\n","\n","# 2. Modelin Son KatmanÄ±nÄ± (Classifier) DeÄŸiÅŸtirme\n","# ResNet50'nin orijinal Ã§Ä±kÄ±ÅŸÄ± 1000 sÄ±nÄ±ftÄ±r (ImageNet). Biz bunu 2 sÄ±nÄ±fa (Normal, Pneumonia) dÃ¼ÅŸÃ¼receÄŸiz.\n","num_ftrs = resnet_model.fc.in_features\n","resnet_model.fc = nn.Linear(num_ftrs, 2)\n","\n","# 3. Modeli GPU'ya TaÅŸÄ±\n","resnet_model = resnet_model.to(device)\n","\n","print(\"\\n--- Model YapÄ±sÄ± (Son Katman) ---\")\n","print(resnet_model.fc) # Ã‡Ä±ktÄ±: Linear(in_features=2048, out_features=2, bias=True)\n","\n","# 4. Optimizer ve Loss AyarlarÄ±\n","# Transfer Learning'de genelde Ã¶ÄŸrenme hÄ±zÄ± (learning rate) biraz daha dÃ¼ÅŸÃ¼k tutulur.\n","resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0001)\n","resnet_criterion = nn.CrossEntropyLoss()\n","\n","# 5. EÄŸitimi BaÅŸlat (Mevcut train_model fonksiyonunu kullanÄ±yoruz)\n","print(\"\\nResNet50 EÄŸitimi BaÅŸlÄ±yor...\")\n","resnet_history = train_model(\n","    model=resnet_model,\n","    train_loader=train_loader,\n","    test_loader=test_loader,\n","    criterion=resnet_criterion,\n","    optimizer=resnet_optimizer,\n","    num_epochs=5 # ResNet gÃ¼Ã§lÃ¼ olduÄŸu iÃ§in 5 epoch bile Ã§ok iyi sonuÃ§ verebilir\n",")"],"metadata":{"id":"PB0wEhyZTlV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SonuÃ§larÄ± Ã§izdir\n","plot_history(resnet_history)\n","\n","# En iyi doÄŸruluk deÄŸerini yazdÄ±r\n","print(f\"ResNet50 En Ä°yi Test DoÄŸruluÄŸu: %{max(resnet_history['test_acc'])*100:.2f}\")"],"metadata":{"id":"t4V2CH9e_PQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vision Transformer (ViT) Modeli\n","\n","from transformers import ViTForImageClassification, ViTConfig\n","\n","# 1. ViT Modelini HazÄ±rlama\n","print(\"ViT Modeli (google/vit-base-patch16-224) Ä°ndiriliyor...\")\n","\n","# Etiket haritalamasÄ± (Raporlamada iÅŸe yarar)\n","id2label = {0: \"NORMAL\", 1: \"PNEUMONIA\"}\n","label2id = {\"NORMAL\": 0, \"PNEUMONIA\": 1}\n","\n","# Modeli yÃ¼kle\n","vit_model_hf = ViTForImageClassification.from_pretrained(\n","    \"google/vit-base-patch16-224\",\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True # Ã‡Ä±kÄ±ÅŸ katmanÄ±nÄ± bizim 2 sÄ±nÄ±fÄ±mÄ±za gÃ¶re yeniden boyutlandÄ±rÄ±r\n",")\n","\n","# 2. Model Wrapper (UyarlayÄ±cÄ±)\n","# Hugging Face modelleri 'output.logits' dÃ¶ndÃ¼rÃ¼r, bizim dÃ¶ngÃ¼mÃ¼z direkt tensor bekliyor.\n","# Bu sÄ±nÄ±f aradaki uyumu saÄŸlar.\n","class ViTWrapper(nn.Module):\n","    def __init__(self, model):\n","        super(ViTWrapper, self).__init__()\n","        self.model = model\n","\n","    def forward(self, x):\n","        # ViT 'pixel_values' argÃ¼manÄ± ister\n","        outputs = self.model(pixel_values=x)\n","        return outputs.logits\n","\n","# Wrapper ile modeli sarÄ±yoruz\n","vit_model = ViTWrapper(vit_model_hf)\n","vit_model = vit_model.to(device)\n","\n","# 3. Optimizer AyarlarÄ±\n","# ViT iÃ§in genelde learning rate biraz daha dÃ¼ÅŸÃ¼k tutulur (2e-5 veya 5e-5 gibi)\n","vit_optimizer = torch.optim.Adam(vit_model.parameters(), lr=5e-5)\n","vit_criterion = nn.CrossEntropyLoss()\n","\n","# 4. EÄŸitimi BaÅŸlat\n","print(\"\\nVision Transformer (ViT) EÄŸitimi BaÅŸlÄ±yor...\")\n","# ViT daha kompleks olduÄŸu iÃ§in yine 5 epoch yeterli olacaktÄ±r, hatta 3. epochta bile sonuÃ§ verebilir.\n","vit_history = train_model(\n","    model=vit_model,\n","    train_loader=train_loader,\n","    test_loader=test_loader,\n","    criterion=vit_criterion,\n","    optimizer=vit_optimizer,\n","    num_epochs=5\n",")"],"metadata":{"id":"gQQix51OKeaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ViT SonuÃ§larÄ±nÄ± Ã‡izdir\n","plot_history(vit_history)\n","\n","# En iyi skoru yazdÄ±r\n","print(f\"ViT En Ä°yi Test DoÄŸruluÄŸu: %{max(vit_history['test_acc'])*100:.2f}\")"],"metadata":{"id":"05fmczBRK2QS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# --- ADIM 1: Veri Seti AyarlarÄ±nÄ± Onarma ---\n","# HafÄ±zadaki test_ds nesnesinin dÃ¶nÃ¼ÅŸÃ¼m fonksiyonunu tekrar tanÄ±mlayÄ±p atÄ±yoruz.\n","# Bu iÅŸlem 'NoneType' hatasÄ±nÄ± ortadan kaldÄ±rÄ±r.\n","\n","def apply_transforms(examples):\n","    examples[\"pixel_values\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image\"]]\n","    return examples\n","\n","# Veri setini eski Ã§alÄ±ÅŸan haline getiriyoruz\n","test_ds.set_transform(apply_transforms)\n","print(\"âœ… Veri seti ayarlarÄ± onarÄ±ldÄ±.\")\n","\n","\n","# --- ADIM 2: Grad-CAM GÃ¶rselleÅŸtirme (Garantili YÃ¶ntem) ---\n","# Bu yÃ¶ntem, ham gÃ¶rÃ¼ntÃ¼ye eriÅŸmek yerine elimizdeki Tensor'u\n","# matematiksel olarak geri Ã§evirip gÃ¶rselleÅŸtirir. Hata riskini sÄ±fÄ±ra indirir.\n","\n","from pytorch_grad_cam import GradCAM\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","# ResNet50'nin son katmanÄ±na kanca atÄ±yoruz\n","target_layers = [resnet_model.layer4[-1]]\n","cam = GradCAM(model=resnet_model, target_layers=target_layers)\n","\n","# Tensor (Normalize edilmiÅŸ) -> Orijinal GÃ¶rÃ¼ntÃ¼ (GÃ¶rselleÅŸtirmek iÃ§in)\n","def inverse_normalize(tensor):\n","    # (C, H, W) -> (H, W, C) formatÄ±na Ã§evir\n","    img = tensor.permute(1, 2, 0).cpu().numpy()\n","    # Normalize iÅŸlemini geri al: (img * std) + mean\n","    # Daha Ã¶nce mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5] kullanmÄ±ÅŸtÄ±k\n","    img = img * 0.5 + 0.5\n","    # 0 ile 1 arasÄ±na sÄ±kÄ±ÅŸtÄ±r\n","    img = np.clip(img, 0, 1)\n","    return img\n","\n","def visualize_gradcam_final(model, dataset, num_samples=4):\n","    model.eval()\n","    print(\"PnÃ¶moni Ã¶rnekleri Ã¼zerinde analiz yapÄ±lÄ±yor...\")\n","\n","    # Rastgele pnÃ¶moni Ã¶rnekleri bulalÄ±m\n","    found_samples = []\n","    indices = np.random.permutation(len(dataset)) # Rastgele tara\n","\n","    for idx in indices:\n","        item = dataset[int(idx)]\n","        if item['label'] == 1: # Sadece PNEUMONIA\n","            found_samples.append(item)\n","            if len(found_samples) == num_samples:\n","                break\n","\n","    plt.figure(figsize=(20, 6))\n","\n","    for i, item in enumerate(found_samples):\n","        # Modelin beklediÄŸi input\n","        input_tensor = item['pixel_values'].unsqueeze(0).to(device)\n","\n","        # 1. Grad-CAM (IsÄ± HaritasÄ±) Hesapla\n","        grayscale_cam = cam(input_tensor=input_tensor, targets=None)\n","        grayscale_cam = grayscale_cam[0, :]\n","\n","        # 2. GÃ¶rÃ¼ntÃ¼yÃ¼ Ä°nsan GÃ¶zÃ¼ Ä°Ã§in Geri Ã‡evir\n","        rgb_img = inverse_normalize(item['pixel_values'])\n","\n","        # 3. BirleÅŸtir\n","        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n","\n","        # 4. Ã‡izdir\n","        plt.subplot(1, num_samples, i + 1)\n","        plt.imshow(visualization)\n","        plt.title(\"Modelin Karar BÃ¶lgesi\\n(KÄ±rmÄ±zÄ± Alan)\")\n","        plt.axis('off')\n","\n","    plt.show()\n","\n","# Ã‡alÄ±ÅŸtÄ±r\n","visualize_gradcam_final(resnet_model, test_ds, num_samples=4)"],"metadata":{"id":"JS-j7KrrXX6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# KayÄ±t yolu\n","save_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Models'\n","os.makedirs(save_path, exist_ok=True)\n","\n","# ResNet Modelini Kaydet\n","torch.save(resnet_model.state_dict(), os.path.join(save_path, 'resnet50_pneumonia.pth'))\n","\n","# ViT Modelini Kaydet\n","torch.save(vit_model.state_dict(), os.path.join(save_path, 'vit_pneumonia.pth'))\n","\n","print(f\"Modeller {save_path} klasÃ¶rÃ¼ne kaydedildi.\")"],"metadata":{"id":"wFjq9qb7ahCY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import pickle\n","\n","# 1. KayÄ±t KlasÃ¶rÃ¼nÃ¼ Belirleme\n","# Proje klasÃ¶rÃ¼nÃ¼zÃ¼n altÄ±na 'Model_Outputs' adÄ±nda bir klasÃ¶r aÃ§alÄ±m\n","project_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi'\n","save_path = os.path.join(project_path, 'Model_Outputs')\n","\n","# KlasÃ¶r yoksa oluÅŸtur\n","os.makedirs(save_path, exist_ok=True)\n","print(f\"ğŸ“‚ KayÄ±t klasÃ¶rÃ¼ hazÄ±rlandÄ±: {save_path}\")\n","\n","# --- 2. Modelleri Kaydetme (.pth dosyalarÄ±) ---\n","print(\"\\nğŸ’¾ Modeller kaydediliyor...\")\n","\n","# Baseline CNN\n","if 'model' in locals():\n","    torch.save(model.state_dict(), os.path.join(save_path, 'baseline_cnn.pth'))\n","    print(\"âœ… Baseline CNN kaydedildi.\")\n","\n","# ResNet50\n","if 'resnet_model' in locals():\n","    torch.save(resnet_model.state_dict(), os.path.join(save_path, 'resnet50.pth'))\n","    print(\"âœ… ResNet50 kaydedildi.\")\n","\n","# Vision Transformer (ViT)\n","if 'vit_model' in locals():\n","    torch.save(vit_model.state_dict(), os.path.join(save_path, 'vit_base.pth'))\n","    print(\"âœ… ViT Model kaydedildi.\")\n","\n","# --- 3. EÄŸitim GeÃ§miÅŸini Kaydetme (Grafikler iÃ§in veriler) ---\n","print(\"\\nğŸ“Š EÄŸitim geÃ§miÅŸleri (History) kaydediliyor...\")\n","\n","histories = {}\n","if 'history' in locals(): histories['cnn'] = history\n","if 'resnet_history' in locals(): histories['resnet'] = resnet_history\n","if 'vit_history' in locals(): histories['vit'] = vit_history\n","\n","# Pickle modÃ¼lÃ¼ ile sÃ¶zlÃ¼k yapÄ±sÄ±nÄ± dosyaya dÃ¶kÃ¼yoruz\n","with open(os.path.join(save_path, 'training_histories.pkl'), 'wb') as f:\n","    pickle.dump(histories, f)\n","\n","print(f\"âœ… TÃ¼m eÄŸitim geÃ§miÅŸleri 'training_histories.pkl' dosyasÄ±na kaydedildi.\")\n","print(\"\\nğŸ‰ TÃ¼m iÅŸlem tamamlandÄ±! Google Drive'Ä±nÄ±zÄ± kontrol edebilirsiniz.\")"],"metadata":{"id":"soZEnrPpbHWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# 1. Tahmin Fonksiyonu (TÃ¼m modeller iÃ§in ortak)\n","def get_all_predictions(model, loader, device):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    # TensÃ¶rleri CPU'ya alÄ±p listeye ekleyeceÄŸiz\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    return all_labels, all_preds\n","\n","# 2. Matris Ã‡izdirme ve Kaydetme Fonksiyonu\n","def plot_and_save_cm(model, model_name, loader, classes, save_folder):\n","    print(f\"\\n--- {model_name} Analizi BaÅŸlÄ±yor ---\")\n","\n","    # Tahminleri al\n","    y_true, y_pred = get_all_predictions(model, loader, device)\n","\n","    # Matrisi Hesapla\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    # Raporu YazdÄ±r (Precision, Recall, F1-Score)\n","    print(classification_report(y_true, y_pred, target_names=classes))\n","\n","    # GÃ¶rselleÅŸtirme\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=classes, yticklabels=classes)\n","    plt.ylabel('GerÃ§ek Etiket (True Label)')\n","    plt.xlabel('Tahmin Edilen (Predicted Label)')\n","    plt.title(f'Confusion Matrix - {model_name}')\n","\n","    # Kaydet\n","    file_path = os.path.join(save_folder, f'confusion_matrix_{model_name}.png')\n","    plt.savefig(file_path)\n","    plt.show()\n","    print(f\"âœ… Grafik kaydedildi: {file_path}\")\n","\n","# --- 3. Ã‡alÄ±ÅŸtÄ±rma KÄ±smÄ± ---\n","\n","# SÄ±nÄ±f isimleri (DokÃ¼mana gÃ¶re: 0=NORMAL, 1=PNEUMONIA)\n","class_names = ['NORMAL', 'PNEUMONIA']\n","save_path = '/content/drive/MyDrive/Colab_Notebooks/Y.Lisans Proje Odevi/Model_Outputs'\n","\n","# a) Baseline CNN\n","if 'model' in locals():\n","    plot_and_save_cm(model, \"Baseline_CNN\", test_loader, class_names, save_path)\n","\n","# b) ResNet50\n","if 'resnet_model' in locals():\n","    plot_and_save_cm(resnet_model, \"ResNet50\", test_loader, class_names, save_path)\n","\n","# c) Vision Transformer (ViT)\n","if 'vit_model' in locals():\n","    plot_and_save_cm(vit_model, \"ViT_Base\", test_loader, class_names, save_path)"],"metadata":{"id":"-vUMIzGdbqTn"},"execution_count":null,"outputs":[]}]}